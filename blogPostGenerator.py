from transformers import GPT2LMHeadModel , GPT2Tokenizer


tokenizer= GPT2Tokenizer.from_pretrained('gpt2-large') 
 #to set up the tokenizer 
 #to convert the sentence into a matrice
model=GPT2LMHeadModel.from_pretrained('gpt2-large',pad_token_id=tokenizer.eos_token_id)

 #to setup the model

tokenizer.decode(tokenizer.eos_token_id)

sentence= str(input('enter the title of the blog'))
input_ids= tokenizer.encode(sentence,return_tensors='pt')  #convert this sentence into a number of representations


tokenizer.decode(input_ids[0][2]) #convert it back into a word

output = model.generate (input_ids,max_length=500,num_beams=5,no_repeat_ngram_size=2,early_stopping=True)

#num beans :in bean search it means the best five words in the sequence 
#no repeat :stops our model from repeating certain sequences over and over again
#in this state we are saying that the sequence of 2 can just be repeated once 
#early stopping means to stop the model once we reatch the point where our model ytiri brk

print(output)
 
#this will show the matrix of words that has been generated by the tokenizer

tokenizer.decode(output[0],skip_special_tokens=True)
